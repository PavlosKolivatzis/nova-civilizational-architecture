## **File 4: testing_framework.md**

```markdown
# NOVA Enhancement - Testing Framework

## Quick Tests

### Test 1: Slot 6 Import Test
```python
# test_slot6_import.py
try:
    from nova.slot6_multicultural_truth_synthesis import (
        MulticulturalTruthSynthesis, 
        CulturalProfile, 
        CulturalContext
    )
    print("‚úÖ Slot 6 import successful")
    
    # Basic instantiation
    engine = MulticulturalTruthSynthesis()
    print("‚úÖ Engine initialization successful")
    
except ImportError as e:
    print(f"‚ùå Import failed: {e}")
except Exception as e:
    print(f"‚ùå Initialization failed: {e}")Test 2: Cultural Analysis Test# test_cultural_analysis.py
from nova.slot6_multicultural_truth_synthesis import MulticulturalTruthSynthesis

def test_cultural_analysis():
    engine = MulticulturalTruthSynthesis()
    
    # Test cases
    test_cases = [
        {
            "name": "European University", 
            "context": {"region": "EU", "language": "de", "empiricism_priority": 0.8}
        },
        {
            "name": "US Tech Company",
            "context": {"region": "US", "clarity_priority": 0.9}
        },
        {
            "name": "Asian Institution",
            "context": {"region": "EA", "foresight_priority": 0.7}
        }
    ]
    
    for case in test_cases:
        profile = engine.analyze_cultural_context(case["name"], case["context"])
        print(f"\n{case['name']}:")
        print(f"  Adaptation Effectiveness: {profile.adaptation_effectiveness:.3f}")
        print(f"  Cultural Context: {profile.cultural_context.value}")
        print(f"  Individualism: {profile.individualism_index:.3f}")
        print(f"  Method Profile: {profile.method_profile}")

if __name__ == "__main__":
    test_cultural_analysis()Test 3: Guardrail Validation Test# test_guardrails.py
from nova.slot6_multicultural_truth_synthesis import (
    MulticulturalTruthSynthesis, 
    CulturalProfile, 
    CulturalContext
)

def test_guardrails():
    engine = MulticulturalTruthSynthesis()
    
    # Create test profile
    profile = CulturalProfile(
        adaptation_effectiveness=0.8,
        power_distance=0.7,  # High power distance
        cultural_context=CulturalContext.COLLECTIVIST
    )
    
    # Test payloads
    test_payloads = [
        {"content": "normal content", "messaging": {}},  # Should pass
        {"content": "spiritual authority guidance", "messaging": {}},  # Should block
        {"content": "normal content", "messaging": {"ideology": "some ideology"}},  # Should warn
    ]
    
    for i, payload in enumerate(test_payloads):
        result = engine.validate_cultural_deployment(profile, "academic", payload)
        print(f"\nTest {i+1}:")
        print(f"  Result: {result.result.value}")
        print(f"  Compliance Score: {result.compliance_score:.3f}")
        print(f"  Violations: {result.violations}")
        print(f"  Transformation Required: {result.transformation_required}")

if __name__ == "__main__":
    test_guardrails()Test 4: Integration Smoke Test# test_integration_smoke.py
import asyncio
import types

def create_mock_slots():
    """Create mock slot managers for testing."""
    
    # Mock Slot 2
    slot2 = types.SimpleNamespace(
        config=types.SimpleNamespace(tri_min_score=0.85),
        process_content=lambda content, session: types.SimpleNamespace(
            tri_score=0.78,
            layer_scores={"OMEGA_SOCIAL_PROOF": 0.4, "SIGMA_ENTROPY_DRIFT": 0.3},
            patterns_detected=["OMEGA_SOCIAL_PROOF", "SIGMA_ENTROPY_DRIFT"]
        )
    )
    
    # Mock Slot 4  
    slot4 = types.SimpleNamespace(
        get_tri_engine_status=lambda: {
            "mathematical_components": {
                "kalman_filter": {"current_estimate": 0.9}
            }
        }
    )
    
    # Real Slot 6
    from nova.slot6_multicultural_truth_synthesis import MulticulturalTruthSynthesis
    slot6 = MulticulturalTruthSynthesis()
    
    # Mock Slot 9
    slot9 = types.SimpleNamespace(
        get_system_status=lambda: {
            "metrics": {"threat_detections": 2, "total_requests": 100}
        }
    )
    
    return {2: slot2, 4: slot4, 6: slot6, 9: slot9}

async def test_deployment_scenario():
    """Test a complete deployment scenario."""
    
    # Import your actual Slot 10 classes here
    # from your_slot10_module import CivilizationalOrchestrator, CivilizationalDeploymentAPI
    
    slot_managers = create_mock_slots()
    
    # Test Slot 6 directly
    slot6 = slot_managers[6]
    
    # Test cultural analysis
    profile = slot6.analyze_cultural_context(
        "Test University",
        {"region": "EU", "language": "en", "empiricism_priority": 0.8}
    )
    
    print("‚úÖ Cultural Analysis:")
    print(f"  Effectiveness: {profile.adaptation_effectiveness:.3f}")
    print(f"  Context: {profile.cultural_context.value}")
# Test guardrail validation
    validation = slot6.validate_cultural_deployment(
        profile, 
        "academic", 
        {"content": "test content", "messaging": {}}
    )
    
    print("‚úÖ Guardrail Validation:")
    print(f"  Result: {validation.result.value}")
    print(f"  Compliance: {validation.compliance_score:.3f}")
    
    # Test metrics
    metrics = slot6.get_performance_metrics()
    print("‚úÖ Performance Metrics:")
    print(f"  Total Analyses: {metrics['synthesis_metrics']['total_analyses']}")
    print(f"  Principle Preservation: {metrics['synthesis_metrics']['principle_preservation_rate']:.3f}")
    
    # If you have Slot 10 available, test full integration:
    # orchestrator = CivilizationalOrchestrator(slot_managers)
    # api = CivilizationalDeploymentAPI(orchestrator)
    # 
    # deployment_request = {
    #     "institutions": [
    #         {"name": "Test University", "type": "academic"}
    #     ],
    #     "cultural_context": {
    #         "Test University": {"region": "EU", "language": "en"}
    #     }
    # }
    # 
    # result = await api.deploy_institutional_network(deployment_request)
    # print("‚úÖ Full Integration Test:")
    # print(f"  Success: {result.get('deployment_summary', {}).get('successful_deployments', 0)}")

if __name__ == "__main__":
    asyncio.run(test_deployment_scenario())Comprehensive Test SuiteTest 5: Performance Metrics Test# test_performance_metrics.py
from nova.slot6_multicultural_truth_synthesis import MulticulturalTruthSynthesis
import time

def test_performance_metrics():
    engine = MulticulturalTruthSynthesis()
    
    print("Initial metrics:")
    metrics = engine.get_performance_metrics()
    print(f"  Analyses: {metrics['synthesis_metrics']['total_analyses']}")
    print(f"  Successful: {metrics['synthesis_metrics']['successful_adaptations']}")
    print(f"  Blocks: {metrics['synthesis_metrics']['guardrail_blocks']}")
    
    # Perform some operations
    for i in range(5):
        profile = engine.analyze_cultural_context(f"Institution_{i}", {"region": "EU"})
        result = engine.validate_cultural_deployment(profile, "academic", {"content": "test"})
    
    print("\nAfter 5 operations:")
    metrics = engine.get_performance_metrics()
    print(f"  Analyses: {metrics['synthesis_metrics']['total_analyses']}")
    print(f"  Successful: {metrics['synthesis_metrics']['successful_adaptations']}")
    print(f"  Principle Preservation: {metrics['synthesis_metrics']['principle_preservation_rate']:.3f}")

if __name__ == "__main__":
    test_performance_metrics()Test 6: Thread Safety Test# test_thread_safety.py
import threading
import time
from nova.slot6_multicultural_truth_synthesis import MulticulturalTruthSynthesis

def test_thread_safety():
    engine = MulticulturalTruthSynthesis()
    results = []
    
    def worker(thread_id):
        for i in range(10):
            profile = engine.analyze_cultural_context(
                f"Institution_{thread_id}_{i}", 
                {"region": "EU"}
            )
            results.append(profile.adaptation_effectiveness)
            time.sleep(0.01)  # Small delay
    
    # Create multiple threads
    threads = []
    for i in range(3):
        t = threading.Thread(target=worker, args=(i,))
        threads.append(t)
        t.start()
    
    # Wait for completion
    for t in threads:
        t.join()
    
    # Check metrics
    metrics = engine.get_performance_metrics()
    print(f"‚úÖ Thread Safety Test:")
    print(f"  Total operations: {len(results)}")
    print(f"  Recorded analyses: {metrics['synthesis_metrics']['total_analyses']}")
    print(f"  Match: {len(results) == metrics['synthesis_metrics']['total_analyses']}")

if __name__ == "__main__":
    test_thread_safety()Slot 10 Integration TestsTest 7: Rate Limiting Test# test_rate_limiting.py (requires patched Slot 10)
import asyncio
import time

async def test_rate_limiting():
    """Test that rate limiting works in patched Slot 10."""
    
    # This test requires your actual Slot 10 implementation
    # from your_slot10_module import InstitutionalNodeDeployer
    
    print("Rate limiting test requires patched Slot 10 code")
    print("Expected behavior:")
    print("  - First 10 deployments/hour: succeed")
    print("  - 11th deployment: rate_limited response")
    print("  - After 1 hour: rate limit resets")
    
    # Example test structure:
    # deployer = InstitutionalNodeDeployer(mock_sim, slot_managers)
    # 
    # # Try 12 rapid deployments
    # for i in range(12):
    #     result = await deployer.deploy_institutional_node(
    #         f"Institution_{i}", "academic"
    #     )
    #     if result.get('reason') == 'rate_limited':
    #         print(f"‚úÖ Rate limit triggered at deployment {i+1}")
    #         break

if __name__ == "__main__":
    asyncio.run(test_rate_limiting())Test 8: Health Monitoring Test# test_health_monitoring.py (requires patched Slot 10)
import asyncio

async def test_health_monitoring():
    """Test cancellable health monitoring."""
    
    print("Health monitoring test requires patched Slot 10 code")
    print("Expected behavior:")
    print("  - Health monitoring starts automatically")
    print("  - Can be cancelled gracefully with stop_event")
    print("  - No hanging tasks after shutdown")
    
    # Example test structure:
    # stop_event = asyncio.Event()
    # 
    # # Start health monitoring
    # health_task = asyncio.create_task(
    #     deployer.monitor_node_health(stop_event=stop_event)
    # )
    # 
    # # Let it run briefly
    # await asyncio.sleep(1)
    # 
    # # Signal stop
    # stop_event.set()
    # 
    # # Wait for graceful shutdown
    # await health_task
    # print("‚úÖ Health monitoring stopped gracefully")

if __name__ == "__main__":
    asyncio.run(test_health_monitoring())Validation ScriptsQuick Validation Script#!/bin/bash
# validate_integration.sh

echo "üîç NOVA Enhancement Validation"
echo "================================"

echo "Testing Slot 6 import..."
python -c "from nova.slot6_multicultural_truth_synthesis import MulticulturalTruthSynthesis; print('‚úÖ Import successful')"

echo "Testing basic functionality..."
python test_slot6_import.py

echo "Testing cultural analysis..."
python test_cultural_analysis.py

echo "Testing guardrails..."
python test_guardrails.py

echo "Testing performance metrics..."
python test_performance_metrics.py

echo "Testing thread safety..."
python test_thread_safety.py

echo "‚úÖ All tests completed"Expected Test ResultsSuccessful Integration IndicatorsImport Tests:‚úÖ No import errors‚úÖ Engine instantiates successfully‚úÖ All classes and enums availableCultural Analysis:‚úÖ Different regions produce different profiles‚úÖ Adaptation effectiveness varies by context‚úÖ Method profiles reflect regional characteristicsGuardrail Tests:‚úÖ Clean content passes validation‚úÖ Forbidden elements trigger blocks‚úÖ Bounds violations suggest transformationsPerformance Tests:‚úÖ Metrics increment correctly‚úÖ Thread-safe operations‚úÖ EMA preservation rate updatesTroubleshooting Failed TestsImport Failures:Check file location: nova/slot6_multicultural_truth_synthesis.pyVerify Python path includes nova directoryCheck for syntax errors in Slot 6 fileCultural Analysis Issues:Verify regional biases are loadingCheck method profile calculationsEnsure adaptation effectiveness is in [0,1] rangeGuardrail Failures:Test forbidden element detectionVerify bounds calculationsCheck transformation logicIntegration Issues:Confirm Slot 10 patches applied correctlyTest mock slot managers workVerify async operations completeProduction Readiness Checklist[ ] All import tests pass[ ] Cultural analysis produces expected ranges[ ] Guardrails block forbidden content[ ] Metrics track correctly[ ] Thread safety confirmed[ ] Rate limiting works (if Slot 10 patched)[ ] Health monitoring cancellable (if Slot 10 patched)[ ] No memory leaks in extended testing[ ] Performance acceptable under loadNext StepsAfter all tests pass:Deploy to staging environmentMonitor metrics in real usageTune parameters based on dataExpand test coverage for edge casesDocument operational proceduresReady for production deployment! üöÄ---