name: temporal-resonance-validation

on:
  schedule:
    # Daily at 09:00 UTC
    - cron: '0 9 * * *'
  workflow_dispatch: # Allow manual trigger for testing

jobs:
  validate-resonance:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Verify Phase 6.0 archive integrity
        run: |
          cd attest/archives
          sha256sum -c phase-6.0-archive.sha256

      - name: Extract temporal variance dataset
        run: |
          python ops/tasks/extract_temporal_variance.py --output ops/data/temporal_variance_dataset.jsonl

      - name: Compute TRSI from temporal data
        run: |
          python -c "
          import sys
          sys.path.insert(0, 'src')
          import json
          from datetime import datetime
          from nova.slots.slot04_tri.core.temporal_schema import TemporalBeliefEntry
          from nova.slots.slot07_production_controls.temporal_resonance import temporal_resonance_engine

          # Load temporal dataset
          entries = []
          try:
              with open('ops/data/temporal_variance_dataset.jsonl', 'r') as f:
                  for line in f:
                      record = json.loads(line.strip())
                      entry = TemporalBeliefEntry(**record)
                      entries.append(entry)
          except FileNotFoundError:
              print('No temporal dataset found, using baseline TRSI=0.5')
              entries = []

          # Compute TRSI
          trsi_value = temporal_resonance_engine.compute_trsi(entries)
          print(f'Computed TRSI: {trsi_value}')

          # Write to validation log
          import os
          os.makedirs('ops/logs', exist_ok=True)
          with open(f'ops/logs/trsi_validation_{datetime.utcnow().strftime(\"%Y%m%d\")}.jsonl', 'w') as f:
              json.dump({
                  'timestamp': datetime.utcnow().isoformat(),
                  'trsi_value': trsi_value,
                  'entries_processed': len(entries),
                  'archive_verified': True
              }, f)
              f.write('\n')
          "

      - name: Parse TRSI log and check drift
        run: |
          # Extract latest TRSI values from computed logs
          LATEST_LOG=$(ls -t ops/logs/trsi_validation_*.jsonl | head -1)
          PREVIOUS_LOG=$(ls -t ops/logs/trsi_validation_*.jsonl | head -2 | tail -1)

          if [ -f "$LATEST_LOG" ]; then
            LATEST_TRSI=$(jq -r '.trsi_value' "$LATEST_LOG")
          else
            echo "No TRSI log found"
            exit 1
          fi

          if [ -f "$PREVIOUS_LOG" ] && [ "$LATEST_LOG" != "$PREVIOUS_LOG" ]; then
            PREVIOUS_TRSI=$(jq -r '.trsi_value' "$PREVIOUS_LOG")
          else
            PREVIOUS_TRSI=$LATEST_TRSI  # No previous data, use same value
          fi

          echo "Latest TRSI: $LATEST_TRSI"
          echo "Previous TRSI: $PREVIOUS_TRSI"

          DRIFT=$(echo "$LATEST_TRSI - $PREVIOUS_TRSI" | bc -l | tr -d -)
          THRESHOLD=0.05

          if (( $(echo "$DRIFT > $THRESHOLD" | bc -l) )); then
            echo "TRSI drift $DRIFT exceeds threshold $THRESHOLD"
            exit 1
          fi

          echo "TRSI drift $DRIFT within acceptable range"

      - name: Generate validation summary
        run: |
          DATE=$(date +%Y%m%d)
          SUMMARY_FILE="ops/logs/trsi_validation_${DATE}.jsonl"

          # Create directory if needed
          mkdir -p ops/logs

          # Output JSONL summary
          echo "{\"timestamp\":\"$(date -Iseconds)\",\"archive_verified\":true,\"trsi_drift_check\":\"passed\",\"drift_value\":$DRIFT}" > "$SUMMARY_FILE"

      - name: Extract today's TRSI stats
        id: trsi
        run: |
          LOG="ops/logs/trsi_validation_$(date -u +%Y%m%d).jsonl"
          if [ ! -f "$LOG" ]; then
            echo "Missing $LOG" >&2; exit 1
          fi
          # grab the last line (latest record)
          LINE=$(tail -n 1 "$LOG")
          # export as step outputs
          echo "trsi_mean=$(echo "$LINE" | jq -r '.trsi_value')" >> $GITHUB_OUTPUT
          echo "drift_mae=$(echo "$LINE" | jq -r '.drift_value // 0')" >> $GITHUB_OUTPUT

      - name: Compute / verify sealed archive hash
        id: seal
        run: |
          # If you keep the precomputed hash file:
          HASH_FILE="attest/archives/phase-6.0-archive.sha256"
          if [ -f "$HASH_FILE" ]; then
            # Verify and extract value
            sha256sum -c "$HASH_FILE"
            VALUE=$(cut -d' ' -f1 "$HASH_FILE")
            echo "sha256=${VALUE}" >> $GITHUB_OUTPUT
          else
            # Or recompute (less ideal):
            FILE="attest/archives/Nova_Phase_6.0_Seal.tar.gz"
            VALUE=$(sha256sum "$FILE" | cut -d' ' -f1)
            echo "sha256=${VALUE}" >> $GITHUB_OUTPUT
          fi

      - name: Generate & validate Phase 7.0-Î² attestation
        id: attest
        env:
          TRSI_MEAN: ${{ steps.trsi.outputs.trsi_mean }}
          DRIFT_MAE: ${{ steps.trsi.outputs.drift_mae }}
          ARCHIVE_SHA256: ${{ steps.seal.outputs.sha256 }}
          GIT_COMMIT: ${{ github.sha }}
          UTC_TIMESTAMP: ${{ github.event.head_commit.timestamp }}
          ATTEST_SCHEMA: attest/phase-7.0-beta.json
          OUTPUT_JSON: attest/latest_phase_7.0_beta.json
        run: |
          chmod +x scripts/validate_phase_7_beta.py
          python scripts/validate_phase_7_beta.py > attest/_latest_phase_7.0_beta.line.json

      - name: Append attestation to daily JSONL
        run: |
          mkdir -p ops/logs
          OUT="ops/logs/trsi_validation_$(date -u +%Y%m%d).jsonl"
          cat attest/_latest_phase_7.0_beta.line.json >> "$OUT"

      - name: Upload validation artifacts
        uses: actions/upload-artifact@v4
        with:
          name: phase-7-beta-attestation-${{ github.run_id }}
          path: |
            attest/latest_phase_7.0_beta.json
            ops/logs/trsi_validation_*.jsonl