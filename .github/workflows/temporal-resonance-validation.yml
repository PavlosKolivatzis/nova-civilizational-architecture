name: temporal-resonance-validation

on:
  schedule:
    # Daily at 09:00 UTC
    - cron: '0 9 * * *'
    # Weekly Monday at 10:00 UTC for RC memory validation
    - cron: '0 10 * * 1'
  workflow_dispatch: # Allow manual trigger for testing

jobs:
  validate-resonance:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Verify Phase 6.0 archive integrity
        run: |
          cd attest/archives
          sha256sum -c phase-6.0-archive.sha256

      - name: Extract temporal variance dataset
        run: |
          python ops/tasks/extract_temporal_variance.py --output ops/data/temporal_variance_dataset.jsonl

      - name: Compute TRSI from temporal data
        run: |
          python -c "
          import sys
          sys.path.insert(0, 'src')
          import json
          from datetime import datetime
          from nova.slots.slot04_tri.core.temporal_schema import TemporalBeliefEntry
          from nova.slots.slot07_production_controls.temporal_resonance import temporal_resonance_engine

          # Load temporal dataset
          entries = []
          try:
              with open('ops/data/temporal_variance_dataset.jsonl', 'r') as f:
                  for line in f:
                      record = json.loads(line.strip())
                      entry = TemporalBeliefEntry(**record)
                      entries.append(entry)
          except FileNotFoundError:
              print('No temporal dataset found, using baseline TRSI=0.5')
              entries = []

          # Compute TRSI
          trsi_value = temporal_resonance_engine.compute_trsi(entries)
          print(f'Computed TRSI: {trsi_value}')

          # Write to validation log
          import os
          os.makedirs('ops/logs', exist_ok=True)
          with open(f'ops/logs/trsi_validation_{datetime.utcnow().strftime(\"%Y%m%d\")}.jsonl', 'w') as f:
              json.dump({
                  'timestamp': datetime.utcnow().isoformat(),
                  'trsi_value': trsi_value,
                  'entries_processed': len(entries),
                  'archive_verified': True
              }, f)
              f.write('\n')
          "

      - name: Parse TRSI log and check drift
        run: |
          # Extract latest TRSI values from computed logs
          LATEST_LOG=$(ls -t ops/logs/trsi_validation_*.jsonl | head -1)
          PREVIOUS_LOG=$(ls -t ops/logs/trsi_validation_*.jsonl | head -2 | tail -1)

          if [ -f "$LATEST_LOG" ]; then
            LATEST_TRSI=$(jq -r '.trsi_value' "$LATEST_LOG")
          else
            echo "No TRSI log found"
            exit 1
          fi

          if [ -f "$PREVIOUS_LOG" ] && [ "$LATEST_LOG" != "$PREVIOUS_LOG" ]; then
            PREVIOUS_TRSI=$(jq -r '.trsi_value' "$PREVIOUS_LOG")
          else
            PREVIOUS_TRSI=$LATEST_TRSI  # No previous data, use same value
          fi

          echo "Latest TRSI: $LATEST_TRSI"
          echo "Previous TRSI: $PREVIOUS_TRSI"

          DRIFT=$(echo "$LATEST_TRSI - $PREVIOUS_TRSI" | bc -l | tr -d -)
          THRESHOLD=0.05

          if (( $(echo "$DRIFT > $THRESHOLD" | bc -l) )); then
            echo "TRSI drift $DRIFT exceeds threshold $THRESHOLD"
            exit 1
          fi

          echo "TRSI drift $DRIFT within acceptable range"

      - name: Generate validation summary
        run: |
          DATE=$(date +%Y%m%d)
          SUMMARY_FILE="ops/logs/trsi_validation_${DATE}.jsonl"

          # Create directory if needed
          mkdir -p ops/logs

          # Output JSONL summary
          echo "{\"timestamp\":\"$(date -Iseconds)\",\"archive_verified\":true,\"trsi_drift_check\":\"passed\",\"drift_value\":$DRIFT}" > "$SUMMARY_FILE"

      - name: Extract today's TRSI stats
        id: trsi
        run: |
          LOG="ops/logs/trsi_validation_$(date -u +%Y%m%d).jsonl"
          if [ ! -f "$LOG" ]; then
            echo "Missing $LOG" >&2; exit 1
          fi
          # grab the last line (latest record)
          LINE=$(tail -n 1 "$LOG")
          # export as step outputs
          echo "trsi_mean=$(echo "$LINE" | jq -r '.trsi_value')" >> $GITHUB_OUTPUT
          echo "drift_mae=$(echo "$LINE" | jq -r '.drift_value // 0')" >> $GITHUB_OUTPUT

      - name: Compute / verify sealed archive hash
        id: seal
        run: |
          # If you keep the precomputed hash file:
          HASH_FILE="attest/archives/phase-6.0-archive.sha256"
          if [ -f "$HASH_FILE" ]; then
            # Verify and extract value
            sha256sum -c "$HASH_FILE"
            VALUE=$(cut -d' ' -f1 "$HASH_FILE")
            echo "sha256=${VALUE}" >> $GITHUB_OUTPUT
          else
            # Or recompute (less ideal):
            FILE="attest/archives/Nova_Phase_6.0_Seal.tar.gz"
            VALUE=$(sha256sum "$FILE" | cut -d' ' -f1)
            echo "sha256=${VALUE}" >> $GITHUB_OUTPUT
          fi

      - name: Generate & validate Phase 7.0-β attestation
        id: attest
        env:
          TRSI_MEAN: ${{ steps.trsi.outputs.trsi_mean }}
          DRIFT_MAE: ${{ steps.trsi.outputs.drift_mae }}
          ARCHIVE_SHA256: ${{ steps.seal.outputs.sha256 }}
          GIT_COMMIT: ${{ github.sha }}
          UTC_TIMESTAMP: ${{ github.event.head_commit.timestamp }}
          ATTEST_SCHEMA: attest/phase-7.0-beta.json
          OUTPUT_JSON: attest/latest_phase_7.0_beta.json
        run: |
          chmod +x scripts/validate_phase_7_beta.py
          python scripts/validate_phase_7_beta.py > attest/_latest_phase_7.0_beta.line.json

      - name: Append attestation to daily JSONL
        run: |
          mkdir -p ops/logs
          OUT="ops/logs/trsi_validation_$(date -u +%Y%m%d).jsonl"
          cat attest/_latest_phase_7.0_beta.line.json >> "$OUT"

      - name: Compute weekly RC memory metrics (Mondays only)
        if: github.event.schedule == '0 10 * * 1'  # Monday 10:00 UTC
        run: |
          python -c "
          import sys
          sys.path.insert(0, 'src')
          import json
          from datetime import datetime, timedelta
          from nova.slots.slot04_tri.core.temporal_schema import TemporalBeliefEntry
          from nova.slots.slot07_production_controls.temporal_resonance import temporal_resonance_engine

          # Load 7 days of TRSI data for memory analysis
          week_ago = datetime.utcnow() - timedelta(days=7)
          trsi_values = []

          # Collect TRSI values from last 7 days of logs
          import glob
          log_files = glob.glob('ops/logs/trsi_validation_*.jsonl')
          log_files.sort(reverse=True)  # Most recent first

          for log_file in log_files[:7]:  # Last 7 days
              try:
                  with open(log_file, 'r') as f:
                      for line in f:
                          record = json.loads(line.strip())
                          timestamp = datetime.fromisoformat(record['timestamp'].replace('Z', '+00:00'))
                          if timestamp >= week_ago:
                              trsi_values.append(record['trsi_value'])
              except (FileNotFoundError, json.JSONDecodeError, KeyError):
                  continue

          if not trsi_values:
              print('No TRSI data found for memory analysis')
              exit(1)

          # Compute memory stability: mean(TRSI) - stdev(TRSI)
          import statistics
          mean_trsi = statistics.mean(trsi_values)
          stdev_trsi = statistics.stdev(trsi_values) if len(trsi_values) > 1 else 0.0
          memory_stability = max(0.0, min(1.0, mean_trsi - stdev_trsi))

          # Compute RIS (simplified for now - will be enhanced with full implementation)
          # RIS = (TRSI × Ethics × (1-Latency))^(1/3)
          ethics_score = 0.95  # Placeholder - from ethics audit
          latency_penalty = 0.05  # Placeholder - from controller metrics
          ris_score = (mean_trsi * ethics_score * (1 - latency_penalty)) ** (1/3)
          ris_score = min(1.0, ris_score)

          print(f'Memory Stability (7-day): {memory_stability}')
          print(f'Resonance Integrity Score: {ris_score}')
          print(f'TRSI samples analyzed: {len(trsi_values)}')

          # Write RC validation log
          rc_log = {
              'timestamp': datetime.utcnow().isoformat(),
              'phase': '7.0-rc',
              'memory_stability': memory_stability,
              'ris_score': ris_score,
              'trsi_samples': len(trsi_values),
              'week_start': week_ago.isoformat(),
              'stability_target': 0.80,
              'ris_target': 0.75
          }

          with open(f'ops/logs/rc_validation_{datetime.utcnow().strftime(\"%Y%m%d\")}.jsonl', 'w') as f:
              json.dump(rc_log, f)
              f.write('\n')
          "

      - name: Validate RC promotion criteria (Mondays only)
        if: github.event.schedule == '0 10 * * 1'  # Monday 10:00 UTC
        run: |
          RC_LOG="ops/logs/rc_validation_$(date -u +%Y%m%d).jsonl"
          if [ ! -f "$RC_LOG" ]; then
            echo "RC validation log not found"
            exit 1
          fi

          MEMORY_STABILITY=$(jq -r '.memory_stability' "$RC_LOG")
          RIS_SCORE=$(jq -r '.ris_score' "$RC_LOG")

          STABILITY_TARGET=0.80
          RIS_TARGET=0.75

          echo "Memory Stability: $MEMORY_STABILITY (target: $STABILITY_TARGET)"
          echo "RIS Score: $RIS_SCORE (target: $RIS_TARGET)"

          if (( $(echo "$MEMORY_STABILITY < $STABILITY_TARGET" | bc -l) )); then
            echo "❌ Memory stability $MEMORY_STABILITY below target $STABILITY_TARGET"
            exit 1
          fi

          if (( $(echo "$RIS_SCORE < $RIS_TARGET" | bc -l) )); then
            echo "❌ RIS score $RIS_SCORE below target $RIS_TARGET"
            exit 1
          fi

          echo "✅ RC promotion criteria met"

      - name: Upload validation artifacts
        uses: actions/upload-artifact@v4
        with:
          name: phase-7-validation-${{ github.run_id }}
          path: |
            attest/latest_phase_7.0_beta.json
            ops/logs/trsi_validation_*.jsonl
            ops/logs/rc_validation_*.jsonl